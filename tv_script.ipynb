{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lobof\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Small LSTM Network to Generate Text for Alice in Wonderland\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"moes_tavern_lines.txt\"\n",
    "source_text = open(filename).read()\n",
    "source_text = source_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(source_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  305284\n",
      "Total Vocab:  67\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(source_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  305184\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "input_data = []\n",
    "target_data = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_input = source_text[i:i + seq_length]\n",
    "    seq_target = source_text[i + seq_length]\n",
    "    input_data.append([char_to_int[char] for char in seq_input])\n",
    "    target_data.append(char_to_int[seq_target])\n",
    "n_patterns = len(input_data)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data_input to be [samples, time steps, features]\n",
    "num_reshape = numpy.reshape(input_data, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "normalize_input = num_reshape/ float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "one_hot = np_utils.to_categorical(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.41791045]\n",
      "  [0.82089552]\n",
      "  [0.52238806]\n",
      "  ...\n",
      "  [0.65671642]\n",
      "  [0.74626866]\n",
      "  [0.67164179]]\n",
      "\n",
      " [[0.82089552]\n",
      "  [0.52238806]\n",
      "  [0.46268657]\n",
      "  ...\n",
      "  [0.74626866]\n",
      "  [0.67164179]\n",
      "  [0.01492537]]\n",
      "\n",
      " [[0.52238806]\n",
      "  [0.46268657]\n",
      "  [0.71641791]\n",
      "  ...\n",
      "  [0.67164179]\n",
      "  [0.01492537]\n",
      "  [0.68656716]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.73134328]\n",
      "  [0.01492537]\n",
      "  [0.46268657]\n",
      "  ...\n",
      "  [0.82089552]\n",
      "  [0.73134328]\n",
      "  [0.52238806]]\n",
      "\n",
      " [[0.01492537]\n",
      "  [0.46268657]\n",
      "  [0.62686567]\n",
      "  ...\n",
      "  [0.73134328]\n",
      "  [0.52238806]\n",
      "  [0.62686567]]\n",
      "\n",
      " [[0.46268657]\n",
      "  [0.62686567]\n",
      "  [0.62686567]\n",
      "  ...\n",
      "  [0.52238806]\n",
      "  [0.62686567]\n",
      "  [0.53731343]]]\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(normalize_input)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(normalize_input.shape[1], normalize_input.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(one_hot.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "305184/305184 [==============================] - 1711s 6ms/step - loss: 2.6616 - acc: 0.2652\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.66162, saving model to weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(normalize_input, one_hot, epochs=1, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" pson: witty. (chuckles)\n",
      "lenny_leonard: great meeting though.\n",
      "bar_rag: yes, that's right, everyone la \"\n",
      " \n",
      " Script Genereated.\n"
     ]
    }
   ],
   "source": [
    "# Load LSTM network and generate text\n",
    "import sys\n",
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(input_data)-1)\n",
    "pattern = input_data[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# Generate random characters\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "prediction = model.predict(x, verbose=0)\n",
    "index = numpy.argmax(prediction)\n",
    "result = int_to_char[index]\n",
    "seq_in = [int_to_char[value] for value in pattern]\n",
    "sys.stdout.write(result)\n",
    "pattern.append(index)\n",
    "pattern = pattern[1:len(pattern)]\n",
    "print ('\\n',\"Script Genereated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
